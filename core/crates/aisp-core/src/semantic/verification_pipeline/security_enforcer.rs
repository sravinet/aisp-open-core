//! Security Enforcer Module
//!
//! Implements enterprise-grade security policy enforcement, violation handling,
//! and incident response for the verification pipeline.

use super::core_types::*;
use crate::error::AispResult;
use crate::semantic::cross_validator::CrossValidationResult;
use std::collections::HashMap;

/// Security enforcer for enterprise-grade security compliance
pub struct SecurityEnforcer {
    pub security_policies: Vec<SecurityPolicy>,
    pub enforcement_rules: Vec<EnforcementRule>,
    pub violation_handlers: HashMap<SecurityViolationType, ViolationHandler>,
    pub audit_logger: AuditLogger,
    pub incident_responder: IncidentResponder,
    active_sessions: HashMap<String, SecuritySession>,
}

/// Active security session tracking
#[derive(Debug, Clone)]
struct SecuritySession {
    session_id: String,
    start_time: std::time::SystemTime,
    security_level: SecurityLevel,
    violations_detected: Vec<SecurityViolationType>,
    enforcement_actions: Vec<String>,
}

/// Security level enumeration
#[derive(Debug, Clone, PartialEq)]
enum SecurityLevel {
    Low,
    Medium,
    High,
    Critical,
}

impl SecurityEnforcer {
    /// Create new security enforcer with strict enterprise policies
    pub fn new() -> Self {
        let mut security_policies = Vec::new();
        security_policies.push(SecurityPolicy {
            policy_name: "ZeroTrustVerification".to_string(),
            enforcement_level: "Strict".to_string(),
        });
        security_policies.push(SecurityPolicy {
            policy_name: "ComprehensiveValidation".to_string(),
            enforcement_level: "Mandatory".to_string(),
        });
        security_policies.push(SecurityPolicy {
            policy_name: "DeceptionDetection".to_string(),
            enforcement_level: "Enhanced".to_string(),
        });

        let mut enforcement_rules = Vec::new();
        enforcement_rules.push(EnforcementRule {
            rule_id: "PARSE_BYPASS_PREVENTION".to_string(),
            condition: "confidence_threshold > 0.95".to_string(),
        });
        enforcement_rules.push(EnforcementRule {
            rule_id: "TYPE_SAFETY_ENFORCEMENT".to_string(),
            condition: "type_safety_score >= 0.90".to_string(),
        });

        let mut violation_handlers = HashMap::new();
        violation_handlers.insert(
            SecurityViolationType::ParseBypass,
            ViolationHandler {
                handler_type: "ImmediateBlock".to_string(),
                response: "Reject document and log critical security event".to_string(),
            }
        );
        violation_handlers.insert(
            SecurityViolationType::DeceptionPattern,
            ViolationHandler {
                handler_type: "EnhancedAnalysis".to_string(),
                response: "Trigger deep deception analysis and human review".to_string(),
            }
        );

        Self {
            security_policies,
            enforcement_rules,
            violation_handlers,
            audit_logger: AuditLogger {
                log_level: "INFO".to_string(),
                destinations: vec!["SecurityLog".to_string(), "ComplianceAudit".to_string()],
            },
            incident_responder: IncidentResponder {
                response_protocols: vec![
                    "LogSecurityEvent".to_string(),
                    "NotifySecurityTeam".to_string(),
                    "UpdateThreatModel".to_string(),
                ],
            },
            active_sessions: HashMap::new(),
        }
    }

    /// Create balanced security enforcer for performance environments
    pub fn new_balanced() -> Self {
        let mut enforcer = Self::new();
        
        // Adjust policies for balanced enforcement
        for policy in &mut enforcer.security_policies {
            if policy.policy_name == "ZeroTrustVerification" {
                policy.enforcement_level = "Balanced".to_string();
            }
        }
        
        // Adjust audit logging for performance
        enforcer.audit_logger.log_level = "WARN".to_string();
        
        enforcer
    }

    /// Start security session for verification pipeline
    pub fn start_security_session(&mut self, session_id: &str) -> AispResult<()> {
        let security_session = SecuritySession {
            session_id: session_id.to_string(),
            start_time: std::time::SystemTime::now(),
            security_level: SecurityLevel::High,
            violations_detected: Vec::new(),
            enforcement_actions: Vec::new(),
        };
        
        self.active_sessions.insert(session_id.to_string(), security_session);
        
        self.log_security_event(
            session_id,
            "SecuritySessionStart",
            "Verification security session initiated",
        )?;
        
        Ok(())
    }

    /// Validate semantic verification results against security policies
    pub fn validate_semantic_results(
        &self, 
        results: &crate::semantic::deep_verifier::DeepVerificationResult
    ) -> AispResult<()> {
        // Check overall confidence threshold
        if results.overall_confidence < 0.90 {
            return self.handle_security_violation(
                SecurityViolationType::LogicInconsistency,
                "Semantic verification confidence below security threshold"
            );
        }

        // Check deception risk
        if results.deception_risk_score > 0.20 {
            return self.handle_security_violation(
                SecurityViolationType::DeceptionPattern,
                "Elevated deception risk detected in semantic analysis"
            );
        }

        // Validate threat level
        match results.security_assessment.threat_level {
            crate::semantic::deep_verifier::ThreatLevel::Critical |
            crate::semantic::deep_verifier::ThreatLevel::High => {
                return self.handle_security_violation(
                    SecurityViolationType::LogicInconsistency,
                    &format!("High threat level detected: {:?}", results.security_assessment.threat_level)
                );
            }
            _ => {}
        }

        Ok(())
    }

    /// Validate behavioral verification results
    pub fn validate_behavioral_results(
        &self,
        results: &crate::semantic::behavioral_verifier::BehavioralVerificationResult
    ) -> AispResult<()> {
        // Check execution safety
        if results.execution_safety_score < 0.85 {
            return self.handle_security_violation(
                SecurityViolationType::BehavioralAnomaly,
                "Behavioral verification safety score below threshold"
            );
        }

        // Check authenticity
        if results.authenticity_score < 0.90 {
            return self.handle_security_violation(
                SecurityViolationType::DeceptionPattern,
                "Authenticity score indicates potential deception"
            );
        }

        // Validate compliance level
        match results.security_assessment.compliance_level {
            crate::semantic::behavioral_verifier::ComplianceLevel::NonCompliant => {
                return self.handle_security_violation(
                    SecurityViolationType::ComplianceViolation,
                    "Behavioral verification compliance failure"
                );
            }
            _ => {}
        }

        Ok(())
    }

    /// Validate adversarial test results
    pub fn validate_adversarial_results(&self, results: &AdversarialTestResults) -> AispResult<()> {
        // Check attack resistance
        if results.attack_resistance_score < 0.80 {
            return self.handle_security_violation(
                SecurityViolationType::TypeSafetyViolation,
                "Attack resistance below acceptable threshold"
            );
        }

        // Check for critical vulnerabilities
        if !results.vulnerabilities_found.is_empty() {
            for vulnerability in &results.vulnerabilities_found {
                if vulnerability.contains("Critical") || vulnerability.contains("High") {
                    return self.handle_security_violation(
                        SecurityViolationType::ParseBypass,
                        &format!("Critical vulnerability found: {}", vulnerability)
                    );
                }
            }
        }

        Ok(())
    }

    /// Validate cross-validation results
    pub fn validate_cross_validation_results(&self, results: &CrossValidationResult) -> AispResult<()> {
        // Check overall consistency
        if results.overall_consistency_score < 0.85 {
            return self.handle_security_violation(
                SecurityViolationType::LogicInconsistency,
                "Cross-validation consistency below security requirement"
            );
        }

        // Check verification confidence
        if results.cross_validation_confidence < 0.80 {
            return self.handle_security_violation(
                SecurityViolationType::LogicInconsistency,
                "Cross-validation confidence insufficient for security approval"
            );
        }

        Ok(())
    }

    /// Generate comprehensive security assessment
    pub fn generate_security_assessment(
        &self,
        semantic: &crate::semantic::deep_verifier::DeepVerificationResult,
        behavioral: &crate::semantic::behavioral_verifier::BehavioralVerificationResult,
        adversarial: &AdversarialTestResults,
        cross_validation: &CrossValidationResult,
    ) -> AispResult<EnterpriseSecurityAssessment> {
        let mut threat_landscape = Vec::new();
        let mut security_posture = "Strong".to_string();

        // Analyze semantic threats
        if semantic.deception_risk_score > 0.10 {
            threat_landscape.push("DeceptionPatterns".to_string());
        }
        if semantic.security_assessment.vulnerability_count > 0 {
            threat_landscape.push("LogicVulnerabilities".to_string());
        }

        // Analyze behavioral threats
        if behavioral.execution_safety_score < 0.90 {
            threat_landscape.push("ExecutionRisks".to_string());
        }

        // Analyze adversarial threats
        if adversarial.successful_attacks > 0 {
            threat_landscape.push("ParseBypass".to_string());
            if adversarial.attack_resistance_score < 0.70 {
                security_posture = "Moderate".to_string();
            }
        }

        // Analyze cross-validation threats
        if cross_validation.overall_consistency_score < 0.90 {
            threat_landscape.push("ConsistencyGaps".to_string());
        }

        // Determine overall posture
        if threat_landscape.len() > 3 {
            security_posture = "Weak".to_string();
        } else if threat_landscape.len() > 1 {
            security_posture = "Moderate".to_string();
        }

        Ok(EnterpriseSecurityAssessment {
            security_posture,
            threat_landscape,
        })
    }

    /// Handle security violation with appropriate response
    fn handle_security_violation(
        &self,
        violation_type: SecurityViolationType,
        description: &str,
    ) -> AispResult<()> {
        eprintln!("SECURITY VIOLATION: {:?} - {}", violation_type, description);

        if let Some(handler) = self.violation_handlers.get(&violation_type) {
            match handler.handler_type.as_str() {
                "ImmediateBlock" => {
                    return Err(crate::error::AispError::SecurityViolation(
                        format!("{:?}: {}", violation_type, description)
                    ));
                }
                "EnhancedAnalysis" => {
                    eprintln!("ENHANCED ANALYSIS TRIGGERED: {}", handler.response);
                    // In production, this would trigger additional analysis
                }
                _ => {
                    eprintln!("SECURITY ACTION: {}", handler.response);
                }
            }
        }

        Ok(())
    }

    /// Log security event for audit trail
    fn log_security_event(
        &self,
        session_id: &str,
        event_type: &str,
        description: &str,
    ) -> AispResult<()> {
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_millis();

        for destination in &self.audit_logger.destinations {
            eprintln!("SECURITY_LOG[{}]: {} - {} - {} - {}", 
                     destination, timestamp, session_id, event_type, description);
        }

        Ok(())
    }

    /// Finalize security session
    pub fn finalize_security_session(&mut self, session_id: &str) -> AispResult<()> {
        if let Some(session) = self.active_sessions.remove(session_id) {
            let duration = session.start_time.elapsed()
                .unwrap_or(std::time::Duration::from_secs(0));

            self.log_security_event(
                session_id,
                "SecuritySessionEnd",
                &format!("Session completed in {}ms with {} violations",
                        duration.as_millis(),
                        session.violations_detected.len()),
            )?;
        }

        Ok(())
    }

    /// Get security statistics for monitoring
    pub fn get_security_statistics(&self) -> SecurityStatistics {
        let active_sessions_count = self.active_sessions.len();
        let total_policies = self.security_policies.len();
        let total_rules = self.enforcement_rules.len();
        
        SecurityStatistics {
            active_sessions: active_sessions_count,
            total_policies,
            total_enforcement_rules: total_rules,
            violation_handlers_configured: self.violation_handlers.len(),
        }
    }
}

/// Security statistics for monitoring
#[derive(Debug, Clone)]
pub struct SecurityStatistics {
    pub active_sessions: usize,
    pub total_policies: usize,
    pub total_enforcement_rules: usize,
    pub violation_handlers_configured: usize,
}

impl Default for SecurityEnforcer {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_security_enforcer_creation() {
        let enforcer = SecurityEnforcer::new();
        assert!(!enforcer.security_policies.is_empty());
        assert!(!enforcer.enforcement_rules.is_empty());
        assert!(!enforcer.violation_handlers.is_empty());
    }

    #[test]
    fn test_balanced_enforcer() {
        let enforcer = SecurityEnforcer::new_balanced();
        
        // Should have modified policies for balanced enforcement
        let zero_trust_policy = enforcer.security_policies
            .iter()
            .find(|p| p.policy_name == "ZeroTrustVerification")
            .unwrap();
        assert_eq!(zero_trust_policy.enforcement_level, "Balanced");
    }

    #[test]
    fn test_security_session_management() {
        let mut enforcer = SecurityEnforcer::new();
        let session_id = "test_session_123";
        
        // Start session
        let start_result = enforcer.start_security_session(session_id);
        assert!(start_result.is_ok());
        assert!(enforcer.active_sessions.contains_key(session_id));
        
        // Finalize session
        let finalize_result = enforcer.finalize_security_session(session_id);
        assert!(finalize_result.is_ok());
        assert!(!enforcer.active_sessions.contains_key(session_id));
    }

    #[test]
    fn test_security_statistics() {
        let mut enforcer = SecurityEnforcer::new();
        enforcer.start_security_session("test_session").unwrap();
        
        let stats = enforcer.get_security_statistics();
        assert_eq!(stats.active_sessions, 1);
        assert!(stats.total_policies > 0);
        assert!(stats.total_enforcement_rules > 0);
        assert!(stats.violation_handlers_configured > 0);
    }
}